{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6b6dec-c0f6-4496-9b75-d74bcba07183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import carla \n",
    "import math \n",
    "import random \n",
    "import time \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Connect the client and set up bp library and spawn points\n",
    "client = carla.Client('carla_server', 2000) \n",
    "world = client.get_world()\n",
    "client.reload_world()\n",
    "bp_lib = world.get_blueprint_library()  \n",
    "spawn_points = world.get_map().get_spawn_points() \n",
    "settings = world.get_settings()\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "settings.synchronous_mode = True\n",
    "world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c94c6a-4c3e-487b-8de9-823e440f3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the ego vehicle\n",
    "vehicle_bp = bp_lib.find('vehicle.lincoln.mkz_2020') \n",
    "vehicle = world.try_spawn_actor(vehicle_bp, spawn_points[79])\n",
    "\n",
    "# Move the spectator behind the vehicle to view it\n",
    "spectator = world.get_spectator() \n",
    "transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4,z=2.5)),vehicle.get_transform().rotation) \n",
    "spectator.set_transform(transform)\n",
    "\n",
    "# Add traffic\n",
    "for i in range(50): \n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle')) \n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f22a80-52d1-4706-9231-5835bfc27a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set traffic in motion\n",
    "for v in world.get_actors().filter('*vehicle*'): \n",
    "    v.set_autopilot(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db29235-7d72-43e3-9b34-89a92ff9fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial camera translation\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "\n",
    "# Add one of each type of camera\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb') \n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "sem_camera_bp = bp_lib.find('sensor.camera.semantic_segmentation') \n",
    "sem_camera = world.spawn_actor(sem_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "inst_camera_bp = bp_lib.find('sensor.camera.instance_segmentation') \n",
    "inst_camera = world.spawn_actor(inst_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "depth_camera_bp = bp_lib.find('sensor.camera.depth') \n",
    "depth_camera = world.spawn_actor(depth_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "dvs_camera_bp = bp_lib.find('sensor.camera.dvs') \n",
    "dvs_camera = world.spawn_actor(dvs_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "opt_camera_bp = bp_lib.find('sensor.camera.optical_flow') \n",
    "opt_camera = world.spawn_actor(opt_camera_bp, camera_init_trans, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb223b5-c5a0-4797-9055-79afafd24349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define respective callbacks\n",
    "def rgb_callback(image, data_dict):\n",
    "    data_dict['rgb_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    \n",
    "def sem_callback(image, data_dict):\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "def inst_callback(image, data_dict):\n",
    "    data_dict['inst_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "def depth_callback(image, data_dict):\n",
    "    image.convert(carla.ColorConverter.LogarithmicDepth)\n",
    "    data_dict['depth_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    \n",
    "def opt_callback(data, data_dict):\n",
    "    image = data.get_color_coded_flow()\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    img[:,:,3] = 255\n",
    "    data_dict['opt_image'] = img\n",
    "    \n",
    "def dvs_callback(data, data_dict):\n",
    "    dvs_events = np.frombuffer(data.raw_data, dtype=np.dtype([\n",
    "                ('x', np.uint16), ('y', np.uint16), ('t', np.int64), ('pol', np.bool)]))\n",
    "    data_dict['dvs_image'] = np.zeros((data.height, data.width, 4), dtype=np.uint8)\n",
    "    dvs_img = np.zeros((data.height, data.width, 3), dtype=np.uint8)\n",
    "    dvs_img[dvs_events[:]['y'], dvs_events[:]['x'], dvs_events[:]['pol'] * 2] = 255\n",
    "    data_dict['dvs_image'][:,:,0:3] = dvs_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ea1188-96b4-452a-9932-c8ab42241588",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'camera_bp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/docker/carla-ros-bridge/test_sensor/Camera sensors.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6361726c615f726f73322d6361726c615f726f735f6272696467652d31227d/home/docker/carla-ros-bridge/test_sensor/Camera%20sensors.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Initialise parameters and data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6361726c615f726f73322d6361726c615f726f735f6272696467652d31227d/home/docker/carla-ros-bridge/test_sensor/Camera%20sensors.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m image_w \u001b[39m=\u001b[39m camera_bp\u001b[39m.\u001b[39mget_attribute(\u001b[39m\"\u001b[39m\u001b[39mimage_size_x\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mas_int()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6361726c615f726f73322d6361726c615f726f735f6272696467652d31227d/home/docker/carla-ros-bridge/test_sensor/Camera%20sensors.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m image_h \u001b[39m=\u001b[39m camera_bp\u001b[39m.\u001b[39mget_attribute(\u001b[39m\"\u001b[39m\u001b[39mimage_size_y\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mas_int()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6361726c615f726f73322d6361726c615f726f735f6272696467652d31227d/home/docker/carla-ros-bridge/test_sensor/Camera%20sensors.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m sensor_data \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mrgb_image\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mzeros((image_h, image_w, \u001b[39m4\u001b[39m)),\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6361726c615f726f73322d6361726c615f726f735f6272696467652d31227d/home/docker/carla-ros-bridge/test_sensor/Camera%20sensors.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39msem_image\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mzeros((image_h, image_w, \u001b[39m4\u001b[39m)),\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6361726c615f726f73322d6361726c615f726f735f6272696467652d31227d/home/docker/carla-ros-bridge/test_sensor/Camera%20sensors.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mdepth_image\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mzeros((image_h, image_w, \u001b[39m4\u001b[39m)),\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6361726c615f726f73322d6361726c615f726f735f6272696467652d31227d/home/docker/carla-ros-bridge/test_sensor/Camera%20sensors.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mdvs_image\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mzeros((image_h, image_w, \u001b[39m4\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6361726c615f726f73322d6361726c615f726f735f6272696467652d31227d/home/docker/carla-ros-bridge/test_sensor/Camera%20sensors.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mopt_image\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mzeros((image_h, image_w, \u001b[39m4\u001b[39m)), \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6361726c615f726f73322d6361726c615f726f735f6272696467652d31227d/home/docker/carla-ros-bridge/test_sensor/Camera%20sensors.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39minst_image\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mzeros((image_h, image_w, \u001b[39m4\u001b[39m))}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'camera_bp' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialise parameters and data\n",
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "\n",
    "\n",
    "sensor_data = {'rgb_image': np.zeros((image_h, image_w, 4)),\n",
    "               'sem_image': np.zeros((image_h, image_w, 4)),\n",
    "               'depth_image': np.zeros((image_h, image_w, 4)),\n",
    "               'dvs_image': np.zeros((image_h, image_w, 4)),\n",
    "               'opt_image': np.zeros((image_h, image_w, 4)), \n",
    "               'inst_image': np.zeros((image_h, image_w, 4))}\n",
    "\n",
    "# OpenCV named window for display\n",
    "cv2.namedWindow('All cameras', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Tile all data in one array\n",
    "top_row = np.concatenate((sensor_data['rgb_image'], sensor_data['sem_image'], sensor_data['inst_image']), axis=1)\n",
    "lower_row = np.concatenate((sensor_data['depth_image'], sensor_data['dvs_image'], sensor_data['opt_image']), axis=1)\n",
    "tiled = np.concatenate((top_row, lower_row), axis=0)\n",
    "\n",
    "# Display with imshow\n",
    "cv2.imshow('All cameras',tiled)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# Set sensors recording\n",
    "camera.listen(lambda image: rgb_callback(image, sensor_data))\n",
    "sem_camera.listen(lambda image: sem_callback(image, sensor_data))\n",
    "inst_camera.listen(lambda image: inst_callback(image, sensor_data))\n",
    "depth_camera.listen(lambda image: depth_callback(image, sensor_data))\n",
    "dvs_camera.listen(lambda image: dvs_callback(image, sensor_data))\n",
    "opt_camera.listen(lambda image: opt_callback(image, sensor_data))\n",
    "\n",
    "# Indefinite while loop\n",
    "while True:\n",
    "    \n",
    "    # Tile camera images into one array\n",
    "    top_row = np.concatenate((sensor_data['rgb_image'], sensor_data['sem_image'], sensor_data['inst_image']), axis=1)\n",
    "    lower_row = np.concatenate((sensor_data['depth_image'], sensor_data['dvs_image'], sensor_data['opt_image']), axis=1)\n",
    "    tiled = np.concatenate((top_row, lower_row), axis=0)\n",
    "       \n",
    "    # Dispaly with imshow\n",
    "    cv2.imshow('All cameras',tiled)\n",
    "    \n",
    "    # Break loop if user presses q\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Stop sensors and destroy OpenCV window\n",
    "camera.stop()\n",
    "sem_camera.stop()\n",
    "inst_camera.stop()\n",
    "depth_camera.stop()\n",
    "dvs_camera.stop()\n",
    "opt_camera.stop()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
